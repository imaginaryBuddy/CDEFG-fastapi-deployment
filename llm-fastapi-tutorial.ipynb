{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup your virtual environment\n",
    "\n",
    "## For Mac\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "```\n",
    "## For Windows \n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "# Install the dependencies\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the following core libraries: \n",
    "\n",
    "- FastAPI\n",
    "- Lanchain\n",
    "- Langchain-openai\n",
    "- Pydantic\n",
    "- Uvicorn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic Models \n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Activity(BaseModel):\n",
    "  \"\"\"\n",
    "  The activity data \n",
    "  \"\"\"\n",
    "  name: str\n",
    "  location: str \n",
    "  category: List[str]\n",
    "  description: str \n",
    "\n",
    "class KeyNote(BaseModel):\n",
    "  \"\"\"\n",
    "  Key note taken by the KeyNoteTaker agent \n",
    "  \"\"\"\n",
    "  title: str = Field(description=\"This should be a short title that captures the key points of the note\")\n",
    "  note: str = Field(description=\"This should be the content of the note\")\n",
    "\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "  \"\"\"\n",
    "  The user profile \n",
    "  \"\"\"\n",
    "  name: str = Field(description=\"The name of the user\")\n",
    "  age: int = Field(description=\"The age of the user\")\n",
    "  gender: str = Field(description=\"The gender of the user\")\n",
    "  interests: List[str] = Field(description=\"The interests of the user\")\n",
    "  location: str = Field(description=\"The location of the user\")\n",
    "  budget: float = Field(description=\"The budget of the user\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(BaseModel):\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agents \n",
    "# Summarisation Agent\n",
    "def create_summarisation_agent():\n",
    "    def summarize(state: AgentState) -> AgentState:\n",
    "        # Get latest discussion\n",
    "        # latest_discussion = state.discussions\n",
    "        llm_summary = AzureChatOpenAI(\n",
    "            azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "            api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "            deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "            model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "            api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "            temperature=0,\n",
    "            max_tokens=1000,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "        )\n",
    "        logging.info(f\"LLM model initialized\")\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=\"\"\"You are a discussion summarizer. \n",
    "            Create a concise summary of the discussion, extracting key points \n",
    "            and insights from the answers. Focus on patterns, unique perspectives, \n",
    "            and potential areas for deeper exploration.\"\"\"),\n",
    "            \n",
    "            HumanMessage(content=f\"\"\"\n",
    "            Question discussed: {state.current_question}\n",
    "            \n",
    "            Answers from participants:\n",
    "            {state.discussions}\n",
    "            \n",
    "            Provide a short summary of the discussion <max 50 words>.\n",
    "            \"\"\")\n",
    "        ]\n",
    "\n",
    "        llm_structured_output_summary = llm_summary.with_structured_output(SummarisationResponse)\n",
    "        response = llm_structured_output_summary.invoke(messages)\n",
    "        logging.info(f\"response create_summarisation_agent: {response}\")\n",
    "        print(\"response create_summarisation_agent: \", response)\n",
    "        timestamp = str(datetime.now().isoformat())\n",
    "        state.summaries.append({timestamp: response.summary})\n",
    "        return state\n",
    "    return summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
